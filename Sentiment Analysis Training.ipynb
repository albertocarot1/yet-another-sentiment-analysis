{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Regression training\n",
    "\n",
    "Since the sentiment analysis tool aims to be able to return binary, 5 stars, or decimal results, the problem will be treated as a regression problem."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import wandb\n",
    "from datasets import load_dataset, Dataset, Value, concatenate_datasets\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33malbertocarot1\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.13.10"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/mnt/DATA/Documents/PycharmProjects/yet-another-sentiment-analysis/wandb/run-20230213_155323-3jd9iq1x</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/albertocarot1/sentiment-analysis/runs/3jd9iq1x' target=\"_blank\">decent-armadillo-26</a></strong> to <a href='https://wandb.ai/albertocarot1/sentiment-analysis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/albertocarot1/sentiment-analysis' target=\"_blank\">https://wandb.ai/albertocarot1/sentiment-analysis</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/albertocarot1/sentiment-analysis/runs/3jd9iq1x' target=\"_blank\">https://wandb.ai/albertocarot1/sentiment-analysis/runs/3jd9iq1x</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/albertocarot1/sentiment-analysis/runs/3jd9iq1x?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x7f3fe6fe7700>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['HF_DATASETS_OFFLINE'] = \"1\"\n",
    "wandb.init(project=\"sentiment-analysis\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset amazon_polarity (/home/alberto/.cache/huggingface/datasets/amazon_polarity/amazon_polarity/3.0.0/a27b32b7e7b88eb274a8fa8ba0f654f1fe998a87c22547557317793b5d2772dc)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/2 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6916a514ab2493d9eff72a341330b59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: sst/default\n",
      "Found cached dataset sst (/home/alberto/.cache/huggingface/datasets/sst/default/1.0.0/b8a7889ef01c5d3ae8c379b84cc4080f8aad3ac2bc538701cbe0ac6416fb76ff)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89a246097f9d4d2da422338bfb225b8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset imdb (/home/alberto/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fe5b941786a54cc0bc2c7870a7332546"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset movie_rationales (/home/alberto/.cache/huggingface/datasets/movie_rationales/default/0.1.0/70ed6b72496c90835e8ee73ebf8d0e49f5ad3aa93f302c8a4b6c886143cfb779)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c43565818c9481ea3d97de4c1c9ff4f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tweet_eval (/home/alberto/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "824c93f50382491f938ae2e57c58d791"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/alberto/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "13900c827d7443878d3021b2bb3b670c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sa_datasets: Dict[str, Dataset] = {}\n",
    "\n",
    "sa_datasets['amzpol'] = load_dataset(\"amazon_polarity\")\n",
    "sa_datasets['sst'] = load_dataset(\"sst\")\n",
    "sa_datasets['ds_imdb'] = load_dataset(\"imdb\")\n",
    "sa_datasets['movrat'] = load_dataset(\"movie_rationales\")\n",
    "sa_datasets['tweet'] = load_dataset(\"tweet_eval\", \"sentiment\")\n",
    "sa_datasets['rotten'] = load_dataset(\"rotten_tomatoes\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Two of the six datasets don't have a validation set. A part of the train set is used for validation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_val_dataset =  sa_datasets['ds_imdb']['train'].train_test_split(test_size=0.125, stratify_by_column='label')\n",
    "sa_datasets['ds_imdb']['train'] = train_val_dataset['train']\n",
    "sa_datasets['ds_imdb']['validation'] = train_val_dataset['test']\n",
    "\n",
    "train_val_dataset =  sa_datasets['amzpol']['train'].train_test_split(test_size=0.125, stratify_by_column='label')\n",
    "sa_datasets['amzpol']['train'] = train_val_dataset['train']\n",
    "sa_datasets['amzpol']['validation'] = train_val_dataset['test']\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The models used are based on the best performing ones on the task, taking into consideration also that the service is expected to be somehow fast, hence discarding the computationally heavy ones.\n",
    "RoBERTa-XLM and XLNet are the two strongest candidates."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "max_num_tokens = 512\n",
    "starting_model = \"xlm-roberta-base\"  # \"xlnet-large-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(starting_model, model_max_length=max_num_tokens, truncation=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(starting_model, num_labels=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The datasets are tokenized, and the labels turned into float values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/3150 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ba0b89cea72483fbf684bb7bfe2d905"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/3150 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7777e21a892d418f896c59dad2b72118"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds_name = 'amzpol', split = 'train' completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Casting the dataset:   0%|          | 0/400 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b866d967aa6743d69b620ea48a1e83f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/400 [00:00<?, ?ba/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a549d2e391b43848e116bf1999d61ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normalize(samples):\n",
    "    # Normalize values for tweets, to have them between 0 and 1\n",
    "    if samples[\"label\"] == 1:\n",
    "        samples[\"label\"] = 0.5\n",
    "    elif samples[\"label\"] == 2:\n",
    "        samples[\"label\"] = 1\n",
    "    return samples\n",
    "\n",
    "for ds_name, ds in sa_datasets.items():\n",
    "    for split in ds.column_names.keys():\n",
    "        if split not in ['train', 'test', 'validation']:\n",
    "            continue\n",
    "        # Get all relevant text in 'text' column and remove useless columns\n",
    "        if ds_name in ['sst', 'financ']:\n",
    "            ds[split] = ds[split].rename_column(\"sentence\", \"text\")\n",
    "            ds[split] = ds[split].remove_columns([\"tokens\", \"tree\"])\n",
    "        elif ds_name == 'movrat':\n",
    "            ds[split] = ds[split].rename_column(\"review\", \"text\")\n",
    "            ds[split] = ds[split].remove_columns(\"evidences\")\n",
    "        elif ds_name == 'amzpol':\n",
    "            df = ds[split].to_pandas()\n",
    "            titles_with_punct = df['title'].str.endswith(('.', '!', '?'))\n",
    "            df.loc[~titles_with_punct, 'title'] += '. '\n",
    "            df.loc[titles_with_punct, 'title'] += ' '\n",
    "            df['text'] = df['title'] + df['content']\n",
    "            ds[split] = Dataset.from_pandas(df)\n",
    "            ds[split] = ds[split].remove_columns([\"title\", \"content\"])\n",
    "        elif ds_name == \"tweet\":\n",
    "            ds[split] = ds[split].map(normalize)\n",
    "\n",
    "        ds[split] = ds[split].cast_column('label', Value(\"float32\"))\n",
    "\n",
    "        ds[split] = ds[split].map(lambda rows: tokenizer(rows['text'], padding='max_length', max_length=max_num_tokens, truncation=True), batched=True)\n",
    "        print(f\"{ds_name = }, {split = } completed.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_metrics_for_regression(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    labels = labels.reshape(-1, 1)\n",
    "\n",
    "    mae = mean_absolute_error(labels, logits)\n",
    "    mse = mean_squared_error(labels, logits)\n",
    "    rmse = mean_squared_error(labels, logits, squared=False)\n",
    "\n",
    "    r2 = r2_score(labels, logits)\n",
    "    single_squared_errors = ((logits - labels).flatten()**2).tolist()\n",
    "\n",
    "    # Compute accuracy, reducing the problem to binary classification on values that are higher/lower than 0.5\n",
    "    accuracy = sum([1 for e in single_squared_errors if e < 0.25]) / len(single_squared_errors)\n",
    "\n",
    "    return {\"rmse\": rmse, \"mse\": mse, \"mae\": mae, \"r2\": r2, \"accuracy\": accuracy}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "training_args = TrainingArguments(\n",
    "    output_dir ='./trained-models',\n",
    "    num_train_epochs = 10,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size,\n",
    "    weight_decay = 0.01,\n",
    "    learning_rate = 2e-5,\n",
    "    save_total_limit = 3,\n",
    "    load_best_model_at_end = True,\n",
    "    metric_for_best_model = 'rmse',\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    # gradient_accumulation_steps=6,\n",
    "    report_to=\"wandb\"\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_sets = []\n",
    "validation_sets = []\n",
    "for ds_name, ds in sa_datasets.items():\n",
    "    for split in ds.column_names.keys():\n",
    "        if split == 'train':\n",
    "            train_sets.append(ds[split])\n",
    "        elif split == 'validation':\n",
    "            validation_sets.append(ds[split])\n",
    "\n",
    "train_set = concatenate_datasets(train_sets)\n",
    "validation_set = concatenate_datasets(validation_sets)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Call the Trainer\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_set , eval_dataset= validation_set,\n",
    "    compute_metrics = compute_metrics_for_regression,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "best_accuracy = trainer.state.best_metric"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.max_memory_allocated(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.get_device_properties(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.max_memory_reserved(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
